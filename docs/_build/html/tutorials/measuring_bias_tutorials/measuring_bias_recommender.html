<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Measuring bias in recommender systems &mdash; holisticai  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom_style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Measuring Bias in clustering" href="measuring_bias_clustering.html" />
    <link rel="prev" title="Measuring Bias in regression" href="measuring_bias_regression.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> holisticai
            <img src="../../_static/holistic_ai.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mitigation.html">Mitigation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../plotting.html">Plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../measuring_bias.html">Measuring bias</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_classification.html"><strong>Measuring Bias in classification</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_regression.html"><strong>Measuring Bias in regression</strong></a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Measuring bias in recommender systems</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Importing-the-data">Importing the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Plotting-and-Data-Exploration">Plotting and Data Exploration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Evaluate-Fairness-of-Model">Evaluate Fairness of Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Item-Fairness">Item Fairness</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#User-fairness---Equality-of-Outcome">User fairness - Equality of Outcome</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_clustering.html"><strong>Measuring Bias in clustering</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_multiclass.html"><strong>Measuring Bias in multiclass classification</strong></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../mitigating_bias.html">Mitigating bias</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">holisticai</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../measuring_bias.html">Measuring bias</a> &raquo;</li>
      <li>Measuring bias in recommender systems</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/measuring_bias_tutorials/measuring_bias_recommender.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Measuring-bias-in-recommender-systems">
<h1>Measuring bias in recommender systems<a class="headerlink" href="#Measuring-bias-in-recommender-systems" title="Permalink to this heading"></a></h1>
<p>This is an introduction to fairness in recommender systems. A recommender system aims to recommend the best item according to the user preference. In this tutorial, we will focus on the task of correctly predicting users’ music preference.</p>
<p>A recommender system can be biased in multiple ways. For example, we may be concerned that the artists in our database will not get equal representation (item fairness). Alternative, our main concern may be that different groups of users (e.g. male/female users) will get different music recommendations (user fairness). In the following, we will show how to explore the data for fairness, and measure these various types of fairness using the holisticai library.</p>
<section id="Importing-the-data">
<h2>Importing the data<a class="headerlink" href="#Importing-the-data" title="Permalink to this heading"></a></h2>
<p>We will start by importing the example dataset, which we host on our library. The <a class="reference external" href="https://www.kaggle.com/datasets/ravichaubey1506/lastfm">datatset</a> contains a set of artists that were downloaded by users. It includes personal information about the user, specifically sex and country of origin. A user can download more than one artist. We will use the column “score”, which contains only 1s for counting the interactions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;../&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">holisticai.datasets</span> <span class="kn">import</span> <span class="n">load_last_fm</span>

<span class="n">bunch</span> <span class="o">=</span> <span class="n">load_last_fm</span><span class="p">()</span>
<span class="n">lastfm</span> <span class="o">=</span> <span class="n">bunch</span><span class="p">[</span><span class="s1">&#39;frame&#39;</span><span class="p">]</span>
<span class="n">lastfm</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user</th>
      <th>artist</th>
      <th>sex</th>
      <th>country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>red hot chili peppers</td>
      <td>f</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>the black dahlia murder</td>
      <td>f</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>goldfrapp</td>
      <td>f</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>dropkick murphys</td>
      <td>f</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>le tigre</td>
      <td>f</td>
      <td>Germany</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>289950</th>
      <td>19718.0</td>
      <td>bob dylan</td>
      <td>f</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>289951</th>
      <td>19718.0</td>
      <td>pixies</td>
      <td>f</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>289952</th>
      <td>19718.0</td>
      <td>the clash</td>
      <td>f</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>289953</th>
      <td>19718.0</td>
      <td>a tribe called quest</td>
      <td>f</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>289954</th>
      <td>19718.0</td>
      <td>radiohead</td>
      <td>f</td>
      <td>Canada</td>
    </tr>
  </tbody>
</table>
<p>289955 rows × 4 columns</p>
</div></div>
</div>
<p>We now need to change the dataframe to an interaction matrix, where every row is a user and every column is an artist. We can use the formatting function provided in the library, the output dataframe can be used as an input to the bias metric functions for recommenders.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import formatters</span>
<span class="kn">from</span> <span class="nn">holisticai.utils</span> <span class="kn">import</span> <span class="n">recommender_formatter</span>

<span class="c1"># Each interaction results in a non-nan entry in the dataframe.</span>
<span class="n">df_pivot</span><span class="p">,</span> <span class="n">p_attr</span> <span class="o">=</span> <span class="n">recommender_formatter</span><span class="p">(</span><span class="n">lastfm</span><span class="p">,</span> <span class="n">users_col</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">groups_col</span><span class="o">=</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span> <span class="n">items_col</span><span class="o">=</span><span class="s1">&#39;artist&#39;</span><span class="p">,</span> <span class="n">scores_col</span><span class="o">=</span><span class="s1">&#39;score&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Plotting-and-Data-Exploration">
<h2>Plotting and Data Exploration<a class="headerlink" href="#Plotting-and-Data-Exploration" title="Permalink to this heading"></a></h2>
<p>We will now move to data exploration, using some of the functions for plotting available in our library.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import plotters</span>
<span class="kn">from</span> <span class="nn">holisticai.bias.plots</span> <span class="kn">import</span> <span class="n">group_pie_plot</span>
<span class="kn">from</span> <span class="nn">holisticai.bias.plots</span> <span class="kn">import</span> <span class="n">long_tail_plot</span>
<span class="kn">from</span> <span class="nn">holisticai.bias.plots</span> <span class="kn">import</span> <span class="n">exposure_diff_plot</span>
<span class="kn">from</span> <span class="nn">holisticai.bias.plots</span> <span class="kn">import</span> <span class="n">exposure_ratio_plot</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Number of Unique Users : &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">df_pivot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Number of Unique Artists : &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">df_pivot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of Unique Users : 15000
Number of Unique Artists : 1004
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># male vs female representation in data</span>
<span class="n">group_pie_plot</span><span class="p">(</span><span class="n">lastfm</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_11_0.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_11_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># country representation in data</span>
<span class="n">group_pie_plot</span><span class="p">(</span><span class="n">lastfm</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_12_0.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_12_0.png" />
</div>
</div>
<p>After an initial exploration of the users demographic, we can explore fairness-related plots. The <code class="docutils literal notranslate"><span class="pre">long_tail_plot</span></code> shows the descendent frequency of the items. In this example, the artists’ popularity seems falls <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">exponentially</a> at a pretty fast rate. This can indicate an issue in terms of items fairness (i.e. if we want all artists to be recommended equally).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the long tail plot shows the distribution of item counts</span>
<span class="n">long_tail_plot</span><span class="p">(</span><span class="n">df_pivot</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_14_0.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_14_0.png" />
</div>
</div>
<p>If we are interested in users’ fairness instead, we may want to compare how often the same artists are presented to different groups of users. Here, we will focus on the comparison between male and female users. Specifically, we calculate the proportion of male users (out of all male users) who have downloaded each artist. We then compare this value to the corresponding proportion of female users.</p>
<p>The holisticai function <code class="docutils literal notranslate"><span class="pre">exposure_diff_plot</span></code> displays the difference in exposure for each item, while <code class="docutils literal notranslate"><span class="pre">exposure_ratio_plot</span></code> measures the ratio in exposure.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sorted exposure differences</span>
<span class="n">group_a</span> <span class="o">=</span> <span class="n">p_attr</span><span class="o">==</span><span class="s1">&#39;f&#39;</span>
<span class="n">group_b</span> <span class="o">=</span> <span class="n">p_attr</span><span class="o">==</span><span class="s1">&#39;m&#39;</span>
<span class="n">exposure_diff_plot</span><span class="p">(</span><span class="n">group_a</span><span class="p">,</span> <span class="n">group_b</span><span class="p">,</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_16_0.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_16_0.png" />
</div>
</div>
<p>The differences in exposures seem to be overall quite small. However, since the number of items is quite large, the exposures are small to start with. In these cases, the exposure ratio may be a more informative choice.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sorted exposure ratios</span>
<span class="n">exposure_ratio_plot</span><span class="p">(</span><span class="n">group_a</span><span class="p">,</span> <span class="n">group_b</span><span class="p">,</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_18_0.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_18_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exposure_ratio_plot</span><span class="p">(</span><span class="n">group_b</span><span class="p">,</span> <span class="n">group_a</span><span class="p">,</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_19_0.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_recommender_19_0.png" />
</div>
</div>
<p>The above plots show that there are artists that are more than 5 times more popular amongst the female subgroup than male, and artists that are more than 20 times more popular amongst male rather than female users.</p>
</section>
<section id="Evaluate-Fairness-of-Model">
<h2>Evaluate Fairness of Model<a class="headerlink" href="#Evaluate-Fairness-of-Model" title="Permalink to this heading"></a></h2>
<p>We will now show how we can calculate various metrics of fairness for recommender systems. In this example, we will cover both metrics for item fairness and for user fairness (equality of outcome).</p>
<section id="Item-Fairness">
<h3>Item Fairness<a class="headerlink" href="#Item-Fairness" title="Permalink to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mat</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">group_a</span> <span class="o">=</span> <span class="n">p_attr</span><span class="o">==</span><span class="s1">&#39;f&#39;</span>
<span class="n">group_b</span> <span class="o">=</span> <span class="n">p_attr</span><span class="o">==</span><span class="s1">&#39;m&#39;</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">holisticai.bias.metrics</span> <span class="kn">import</span> <span class="n">aggregate_diversity</span>
<span class="n">aggregate_diversity</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1.0
</pre></div></div>
</div>
<p>The above metric shows all artists are shown to at least one user. This makes sense as the dataset is created from the interaction of users with particular artists.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">holisticai.bias.metrics</span> <span class="kn">import</span> <span class="n">gini_index</span>
<span class="n">gini_index</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.4014296448409511
</pre></div></div>
</div>
<p>The Gini Index is often used in the context of recommender systems as a measure of how unequal the distribution of exposure is over artists. A value of 0 would indicate perfect fairness, a flat distribution. A value of 1 would be maximally unequal. In this case the GINI Index is 0.4, indicating a considerable amount of difference in exposures overall between different artists. Ultimately this is created by the ‘will of the people’ so cannot be considered an ethical issue, but is worth noticing.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">holisticai.bias.metrics</span> <span class="kn">import</span> <span class="n">recommender_bias_metrics</span>
<span class="n">recommender_bias_metrics</span><span class="p">(</span><span class="n">mat_pred</span><span class="o">=</span><span class="n">mat</span><span class="p">,</span> <span class="n">metric_type</span><span class="o">=</span><span class="s1">&#39;item_based&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Aggregate Diversity</th>
      <td>1.000000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>GINI index</th>
      <td>0.401430</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Exposure Distribution Entropy</th>
      <td>6.614933</td>
      <td>-</td>
    </tr>
    <tr>
      <th>Average Recommendation Popularity</th>
      <td>522.811846</td>
      <td>-</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Above we have batch plotted all item_based metrics for recommender bias task. For instance observe the Average Recommendation Popularity is 522, meaning that on average a user will interact with an artist that has 522 total interactions.</p>
</section>
</section>
<section id="User-fairness---Equality-of-Outcome">
<h2>User fairness - Equality of Outcome<a class="headerlink" href="#User-fairness---Equality-of-Outcome" title="Permalink to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">holisticai.bias.metrics</span> <span class="kn">import</span> <span class="n">exposure_l1</span>
<span class="n">exposure_l1</span><span class="p">(</span><span class="n">group_a</span><span class="p">,</span> <span class="n">group_b</span><span class="p">,</span> <span class="n">mat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.22982410678782372
</pre></div></div>
</div>
<p>Above we compute the total variation distance between the exposure distribution of males and females. The minimum value for this metric is 0 indicating the two subgroups are exposed to the artists in exactly the same way, the maximum value is 1 indicating a maximal separation in exposures between the two groups. In this case the value of 0.22 shows there is a difference between the taste of males and females in music, but not a drastic one.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">holisticai.bias.metrics</span> <span class="kn">import</span> <span class="n">recommender_bias_metrics</span>
<span class="n">recommender_bias_metrics</span><span class="p">(</span><span class="n">group_a</span><span class="p">,</span> <span class="n">group_b</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">metric_type</span><span class="o">=</span><span class="s1">&#39;equal_outcome&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Mean Absolute Deviation</th>
      <td>0.000008</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Exposure Total Variation</th>
      <td>0.229824</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Exposure KL Divergence</th>
      <td>0.168021</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Above we show the batch computation for equality of outcome metrics in a recommender systems setting.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="measuring_bias_regression.html" class="btn btn-neutral float-left" title="Measuring Bias in regression" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="measuring_bias_clustering.html" class="btn btn-neutral float-right" title="Measuring Bias in clustering" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Holistic AI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
